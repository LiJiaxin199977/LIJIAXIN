{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\n",
    "    \"https://vincentarelbundock.github.io/Rdatasets/csv/dplyr/storms.csv\", nrows=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import requests\n",
    "\n",
    "url = \"https://api.ons.gov.uk/timeseries/JP9Z/dataset/UNEM/data\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"请求状态码: {response.status_code}\")\n",
    "print(f\"返回的原始内容: {response.text}\")\n",
    "#The interface API is no longer available, so I can't get the data at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above, I made changes to the code. Using the FRED API key, query series_id=“LMJVTTUVGBM647S”, which is the series number of the UK job vacancies (in thousands).167ccd5ae95c579ae64d6b1295c563feThis is Jie Xu's FRED API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 替换为你的 FRED API key\n",
    "api_key = \"167ccd5ae95c579ae64d6b1295c563fe\"\n",
    "url = f\"https://api.stlouisfed.org/fred/series/observations?series_id=LMJVTTUVGBM647S&api_key={api_key}&file_type=json\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()['observations']\n",
    "\n",
    "# 提取日期和职位空缺数量，过滤掉非数字数据\n",
    "dates = [item['date'] for item in data]\n",
    "values = []\n",
    "for item in data:\n",
    "    try:\n",
    "        values.append(float(item['value']))\n",
    "    except ValueError:\n",
    "        values.append(None)  # 使用 None 表示无效数据\n",
    "\n",
    "# 创建 DataFrame 并去除无效数据\n",
    "df = pd.DataFrame({'Date': dates, 'Vacancies': values})\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 绘制折线图\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['Date'], df['Vacancies'], label='UK Job Vacancies (Service Industries)', color='blue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Vacancies (Thousands)')\n",
    "plt.title('UK Job Vacancies (Service Industries)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "\n",
    "df_u = web.DataReader(\"LRHUTTTTGBM156S\", \"fred\")\n",
    "\n",
    "df_u.plot(title=\"UK unemployment (percent)\", legend=False, ylim=(2, 6), lw=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = \"https://databank.worldbank.org/source/millennium-development-goals/Series/EN.ATM.CO2E.KT\"\n",
    "html = requests.get(url).content\n",
    "df = pd.read_html(html)[0]\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I went to Getting Data-Coding for Economists based on the code, but could not get the data. Then, I went to https://datacatalog.worldbank.org/indicator/b66c366b-bdce-eb11-bacc-000d3a596ff0/CO2-emissions--metric-tons-per-capita. this site to get the Data and the page keeps reporting an error:\n",
    "An error occurs.\n",
    "This could be due to\n",
    "\n",
    "Our network is unusually busy\n",
    "The server is currently unavailable\n",
    "Please try again later or contact data@worldbank.org\n",
    "\n",
    "Error ID: 9bcb1bcd7bd91946aaddafba37719f72. So I can only use excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件，假设数据在第一个工作表\n",
    "df = pd.read_excel('data\\EN.ATM.CO2E.PC.xlsx')\n",
    "\n",
    "# 重命名列（如果需要），确保列名与你的要求一致，这里假设原始列名分别为'Country Name'、'Year'、'EN.ATM.CO2E.KT'\n",
    "df.rename(columns={'Country Name': 'country', 'Year': 'year', 'EN.ATM.CO2E.KT': 'EN.ATM.CO2E.PC'}, inplace=True)\n",
    "\n",
    "# 选择需要的列并按照人均二氧化碳排放量排序\n",
    "selected_data = df[['country', 'year', 'EN.ATM.CO2E.PC']].sort_values('EN.ATM.CO2E.PC')\n",
    "\n",
    "# 显示处理后的数据表格\n",
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=\"country\", y=\"EN.ATM.CO2E.PC\", data=df.reset_index(), ax=ax)\n",
    "ax.set_title(r\"CO$_2$ (metric tons per capita)\", loc=\"right\")\n",
    "plt.suptitle(\"The USA leads the world on per-capita emissions\", y=1.01)\n",
    "for key, spine in ax.spines.items():\n",
    "    spine.set_visible(False)\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.yaxis.tick_right()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this link: https://stats.oecd.org/SDMX-JSON/data/PDB_LV/GBR+FRA+CAN+ITA+DEU+JPN+USA.T_GDPEMP.CPC/all?startTime=2010 can no longer be found.404 - File or directory not found.\n",
    "The resource you are looking for may have been deleted, renamed, or is temporarily unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://aeturrell.com/research\"\n",
    "page = requests.get(url)\n",
    "page.text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "print(soup.prettify()[60000:60500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all paragraphs\n",
    "all_paras = soup.find_all(\"p\")\n",
    "# Just show one of the paras\n",
    "all_paras[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paras[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = soup.find_all(\"div\", class_=\"project-content listing-pub-info\")\n",
    "projects = [x.text.strip() for x in projects]\n",
    "projects[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scraper(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # 检查请求是否成功，若不成功则抛出异常\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return soup.title.string if soup.title else \"No title found\"\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching page {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "start, stop = 0, 50\n",
    "root_url = \"www.codingforeconomists.com/page=\"\n",
    "info_on_pages = []\n",
    "for i in range(start, stop):\n",
    "    url = root_url + str(i)\n",
    "    info = scraper(url)\n",
    "    info_on_pages.append(info)\n",
    "\n",
    "print(info_on_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = pd.read_html(\n",
    "    \"https://simple.wikipedia.org/wiki/FIFA_World_Cup\", match=\"Sweden\"\n",
    ")\n",
    "# Retrieve first and only entry from list of dataframes\n",
    "df = df_list[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "\n",
    "def read_pdf_text(file_path):\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "pdf_file_path = Path(\"data/pdf_with_table.pdf\")\n",
    "pdf_text = read_pdf_text(pdf_file_path)\n",
    "print(pdf_text[:220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import os\n",
    "\n",
    "# 设置 PDF 文件路径\n",
    "pdf_path = os.path.join('data', 'pdf_with_table.pdf')\n",
    "\n",
    "# 使用 tabula 读取 PDF 中的表格数据\n",
    "tables = tabula.read_pdf(pdf_path, pages='all')\n",
    "\n",
    "# 打印第一个表格的数据（你可以根据实际需求修改处理方式）\n",
    "if len(tables) > 0:\n",
    "    print(tables[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
